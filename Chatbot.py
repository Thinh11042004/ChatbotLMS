# Chatbot.py (Refactor to√†n b·ªô v·ªõi l·ª±a ch·ªçn Prompt ƒë·ªông, ƒë√°nh gi√°, log, g·ª£i √Ω)

from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain.retrievers import ContextualCompressionRetriever
from reranker import SentenceTransformersReranker
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from dotenv import load_dotenv
from prompts import (
    QA_CHAIN_PROMPT,
    SUMMARY_PROMPT,
    STUDENT_SUPPORT_PROMPT,
    PREREQUISITE_PROMPT,
    CLO_EXPLAIN_PROMPT,
    ROADMAP_PROMPT,
    WARNING_PROMPT,
    COMPARISON_PROMPT,
    SKILL_PROMPT,
    WORKLOAD_PROMPT,
    TOPIC_LIST_PROMPT 
)


load_dotenv()
def choose_prompt(query: str):
    q = query.lower()
    if "t√≥m t·∫Øt" in q or "n·ªôi dung ch√≠nh" in q:
        return SUMMARY_PROMPT
    elif "ti√™n quy·∫øt" in q or "m√¥n tr∆∞·ªõc" in q:
        return PREREQUISITE_PROMPT
    elif "chu·∫©n ƒë·∫ßu ra" in q or "clo" in q:
        return CLO_EXPLAIN_PROMPT
    elif "t∆∞ v·∫•n" in q or "l·ªô tr√¨nh" in q:
        return ROADMAP_PROMPT
    elif "kh√≥" in q or "c·∫£nh b√°o" in q:
        return WARNING_PROMPT
    elif "so s√°nh" in q or "kh√°c bi·ªát" in q:
        return COMPARISON_PROMPT
    elif "k·ªπ nƒÉng" in q:
        return SKILL_PROMPT
    elif "n·∫∑ng" in q or "t·ªën th·ªùi gian" in q:
        return WORKLOAD_PROMPT
    elif "nƒÉm nh·∫•t" in q or "g·ª£i √Ω" in q:
        return STUDENT_SUPPORT_PROMPT
    elif "topic" in q or "ch·ªß ƒë·ªÅ" in q or "n·ªôi dung" in q or "h·ªçc g√¨" in q or "c√≥ trong h·ªçc ph·∫ßn" in q:
        return TOPIC_LIST_PROMPT  
    else:
        return QA_CHAIN_PROMPT

# === Model & Embedding ===
llm = ChatOpenAI(temperature=0, model="gpt-4")
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")

# === Load FAISS ===
db = FAISS.load_local("faiss_index", embedding_model, allow_dangerous_deserialization=True)

# === Reranker ===
reranker = SentenceTransformersReranker(model_name="cross-encoder/ms-marco-MiniLM-L-6-v2")
retriever = db.as_retriever(search_kwargs={"k": 6})
compression_retriever = ContextualCompressionRetriever(
    base_compressor=reranker,
    base_retriever=retriever,
)

# === CLI Giao di·ªán ===
print("\U0001f50d ƒê·∫∑t c√¢u h·ªèi v·ªÅ h·ªçc ph·∫ßn (g√µ 'exit' ƒë·ªÉ tho√°t):\n")

while True:
    query = input("üßë‚Äçüè´ B·∫°n h·ªèi g√¨? > ").strip()
    if query.lower() == "exit":
        break

    prompt = choose_prompt(query)

    print("\n[1] üîç RETRIEVAL (T·ª´ FAISS):")
    retrieved_docs = retrieved_docs = retriever.invoke(query)

    for i, doc in enumerate(retrieved_docs):
        print(f"--- Doc {i+1} ---\n{doc.page_content[:300]} ...\n")

    print("[2] üìä RERANKED (Sau khi rerank):")
    reranked_docs = compression_retriever.invoke(query)

    for i, doc in enumerate(reranked_docs):
        print(f"‚≠ê Top {i+1}\n{doc.page_content[:300]} ...\n")

    # Chain kh·ªõi t·∫°o sau khi bi·∫øt prompt
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=compression_retriever,
        return_source_documents=True,
        chain_type_kwargs={"prompt": prompt}
    )

    print("[3] ü§ñ LLM ANSWER:")
    result = qa_chain.invoke(query)
    print(result["result"])

    print("\n[4] üìå Ngu·ªìn t√†i li·ªáu ")
    for doc in result["source_documents"]:
        print("- " + doc.page_content[:150].replace("\n", " ") + "...")

    # === Logging ===
    with open("log.txt", "a", encoding="utf-8") as f:
        f.write(f"\n=== LOG {query} ===\n")
        f.write(f"Prompt: {prompt.template[:50]}...\n")
        f.write(f"RETRIEVED: {len(retrieved_docs)} docs\n")
        f.write(f"RERANKED TOP: {reranked_docs[0].page_content[:120]}...\n")
        f.write(f"ANSWER: {result['result']}\n")
        f.write("="*50 + "\n")

    print("\n" + "="*80 + "\n")
